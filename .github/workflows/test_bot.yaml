name: Test Bot

on:
  workflow_dispatch:

concurrency:
  group: ${{ github.workflow }}
  cancel-in-progress: false

jobs:
  forecast_job:
    runs-on: ubuntu-latest

    steps:
      - name: Check out repository
        uses: actions/checkout@v3

      - uses: actions/setup-python@v4
        with:
          python-version: "3.11"

      - name: Install poetry
        uses: snok/install-poetry@v1
        with:
          virtualenvs-create: true
          virtualenvs-in-project: true
          installer-parallel: true

      - name: Install dependencies
        run: |
          poetry lock --no-interaction
          poetry install --no-interaction --no-root
          poetry run pip install torch transformers accelerate

      - name: Cache Hugging Face model
        id: cache-hf-model
        uses: actions/cache@v4
        with:
          path: ~/.cache/huggingface
          key: hf-model-${{ runner.os }}-${{ hashFiles('**/main.py') }}

      - name: Preload Forecasting LLM
        run: |
          mkdir -p ~/.cache/huggingface/hub
          python - <<'PYCODE'
          from transformers import AutoModelForCausalLM, AutoTokenizer
          model_name = "haphazardlyinc/ForecastingGraniteFinal"
          AutoTokenizer.from_pretrained(model_name)
          AutoModelForCausalLM.from_pretrained(model_name)
          print("âœ… Model cached successfully")
          PYCODE

      - name: Run bot
        run: |
          poetry run python -u main.py --mode test_questions
        env:
          LOCAL_MODEL_PATH: "haphazardlyinc/ForecastingGraniteFinal"
          METACULUS_TOKEN: ${{ secrets.METACULUS_TOKEN }}
          PERPLEXITY_API_KEY: ${{ secrets.PERPLEXITY_API_KEY }}
          EXA_API_KEY: ${{ secrets.EXA_API_KEY }}
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          OPENROUTER_API_KEY: ${{ secrets.OPENROUTER_API_KEY }}
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
          ASKNEWS_CLIENT_ID: ${{ secrets.ASKNEWS_CLIENT_ID }}
          ASKNEWS_SECRET: ${{ secrets.ASKNEWS_SECRET }}
